{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secrets\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from openrouteservice import client\n",
    "import shapely\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSUS_KEY = secrets.CENSUS_API_KEY\n",
    "\n",
    "\n",
    "ORS_KEY = secrets.ORS_API_KEY\n",
    "ORS_URL = 'https://api.openrouteservice.org/v2/isochrones/foot-walking'\n",
    "\n",
    "CACHE_PATH = './Cache/Cache.json'\n",
    "CACHE_VAR = {}\n",
    "\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter?\"\n",
    "overpass_query_markets = '''[out:json]\n",
    "[timeout:25]\n",
    ";\n",
    "area(3600175905)->.searchArea;\n",
    "(\n",
    "  node\n",
    "    [\"shop\"=\"supermarket\"]\n",
    "    (area.searchArea);\n",
    "  way\n",
    "    [\"shop\"=\"supermarket\"]\n",
    "    (area.searchArea);\n",
    "  relation\n",
    "    [\"shop\"=\"supermarket\"]\n",
    "    (area.searchArea);\n",
    "  node\n",
    "    [\"shop\"=\"grocery\"]\n",
    "    (area.searchArea);\n",
    "  way\n",
    "    [\"shop\"=\"grocery\"]\n",
    "    (area.searchArea);\n",
    "  relation\n",
    "    [\"shop\"=\"grocery\"]\n",
    "    (area.searchArea);\n",
    "  node\n",
    "    [\"shop\"=\"greengrocer\"]\n",
    "    (area.searchArea);\n",
    "  way\n",
    "    [\"shop\"=\"greengrocer\"]\n",
    "    (area.searchArea);\n",
    "  relation\n",
    "    [\"shop\"=\"greengrocer\"]\n",
    "    (area.searchArea);\n",
    ");\n",
    "out center;\n",
    ">;\n",
    "out skel qt;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cache(cache_path):\n",
    "    '''\n",
    "        Opens the cache with the file path provided as a dictionary; if no cache is present,\n",
    "        creates a cache dictionary.\n",
    "\n",
    "        Returns the resultant cache dictionary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cache_path: str\n",
    "            The path to a cache file, if such a file exists.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing cached information stored in the form of a json.\n",
    "        '''\n",
    "    try:\n",
    "        with open(cache_path, 'r') as cache_file:\n",
    "                cache = json.load(cache_file)\n",
    "    except:\n",
    "        cache = {}\n",
    "\n",
    "    return cache\n",
    "\n",
    "\n",
    "def save_cache(cache_data, cache_name):\n",
    "    '''\n",
    "        Saves a cache dictionary to the filepath provided.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cache_name: dict\n",
    "            A dictionary containing cached webpage information.\n",
    "\n",
    "        cache_path: str\n",
    "            The file path where the cache is to be saved.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        '''\n",
    "    if cache_name is not None and CACHE_VAR is not None:\n",
    "        updated_cache = CACHE_VAR.copy()\n",
    "        updated_cache[cache_name] = cache_data\n",
    "    else:\n",
    "        updated_cache = cache_data\n",
    "\n",
    "    with open(CACHE_PATH, 'w') as cache_file:\n",
    "        json.dump(updated_cache, cache_file, indent=2)\n",
    "\n",
    "\n",
    "def construct_unique_key(params, api_url):\n",
    "    '''\n",
    "        Constructs a unique key for a webpage (to be used in this program's\n",
    "        cache) from supplied parameters and an API URL.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params: dict\n",
    "            A dictionary containing search parameters.\n",
    "\n",
    "        api_url: string\n",
    "            The location of an API. Defaults to global API_URL.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            A unique key.\n",
    "        '''\n",
    "    param_strings = []\n",
    "    connector = '_'\n",
    "    for k in params.keys():\n",
    "        param_strings.append(f'{k}_{params[k]}')\n",
    "    unique_key = api_url + connector + connector.join(param_strings)\n",
    "    return unique_key\n",
    "\n",
    "\n",
    "def call_API_with_cache(url, params, cache_name, reset_cache=False):\n",
    "    '''\n",
    "        Manages API calls using the provided cache of API-derived data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url: string\n",
    "            The location of a resource to be requested.\n",
    "\n",
    "        params: dict\n",
    "            A dictionary containing search parameters; defaults to None.\n",
    "\n",
    "        cache: dict\n",
    "            A dictionary containing previously obtained data.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            The JSON returned by the API call, formatted as a dictionary.\n",
    "        '''\n",
    "\n",
    "    if reset_cache == False:\n",
    "        temp_cache = CACHE_VAR.setdefault(cache_name, {})\n",
    "    else:\n",
    "        temp_cache = {}\n",
    "\n",
    "    if params is not None:\n",
    "        key = construct_unique_key(params, url)\n",
    "    else:\n",
    "        key = url\n",
    "\n",
    "    if key in temp_cache.keys():\n",
    "        print(f\"Using Cache: {url}\")\n",
    "        content = temp_cache[key]\n",
    "        return content\n",
    "    else:\n",
    "        print(f\"Fetching: {url}\")\n",
    "        if params is not None:\n",
    "            content = requests.get(url=url, params=params).json()\n",
    "        else:\n",
    "            content = requests.get(url=url).json()\n",
    "\n",
    "        temp_cache[key] = content\n",
    "        save_cache(temp_cache, cache_name)\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_data(refresh=False):\n",
    "    '''TODO: Docstring\n",
    "\n",
    "    Fetches market data, saves and returns as GeoJSON'''\n",
    "\n",
    "    geographic_elements = {'type':'FeatureCollection',\n",
    "                      'name':'markets',\n",
    "                      'features':[]}\n",
    "\n",
    "\n",
    "    results = call_API_with_cache(url=overpass_url,\n",
    "                                  params={'data':overpass_query_markets},\n",
    "                                  cache_name='markets', reset_cache=refresh)\n",
    "\n",
    "    for element in results['elements']:\n",
    "        if 'tags' in element:\n",
    "            geodict = {'type':'Point'}\n",
    "            propdict = {'id':element['id']}\n",
    "\n",
    "            if element['type'] == 'node' and 'tags' in element:\n",
    "                lon = element['lon']\n",
    "                lat = element['lat']\n",
    "                geodict['coordinates'] = [lon, lat]\n",
    "\n",
    "            elif 'center' in element:\n",
    "                lon = element['center']['lon']\n",
    "                lat = element['center']['lat']\n",
    "                geodict['coordinates'] = [lon, lat]\n",
    "\n",
    "            for key, value in element['tags'].items():\n",
    "                propdict[key] = value\n",
    "\n",
    "            geographic_elements['features'].append({'type':'Feature',\n",
    "                                       'geometry':geodict,\n",
    "                                       'properties':propdict})\n",
    "    \n",
    "    \n",
    "    markets_data = gpd.read_file(json.dumps(geographic_elements))\n",
    "    markets_data['wkb_geometry'] = markets_data['geometry'].apply(lambda item: item.wkb)\n",
    "    markets_data['addr'] = markets_data.apply(lambda row: f\"{row['addr:housenumber']} {row['addr:street']}, {row['addr:city']}\", axis=1)\n",
    "    markets_data['addr'] = markets_data['addr'].apply(lambda x: None if (str(x).find('None') != -1) else x)\n",
    "    \n",
    "    census_tracts = gpd.read_file('Geospatial_Data/NYC_Tracts.geojson').to_crs('epsg:4326')\n",
    "    fields_to_keep = ('id', 'name', 'alt_name', 'addr', 'shop', 'opening_hours', 'phone', 'GEOID','wkb_geometry')\n",
    "    \n",
    "    markets_data_with_tract = gpd.sjoin(markets_data, census_tracts, how='left', op='intersects')\n",
    "    markets_data_with_tract.drop(columns=[column for column in markets_data_with_tract.columns \n",
    "                                          if column not in fields_to_keep], inplace=True)\n",
    "\n",
    "                                                                    \n",
    "    #markets_data_with_tract.to_file('Geospatial_Data/markets.geojson', driver='GeoJSON')\n",
    "    \n",
    "    \n",
    "    #ADD DATABASE-WRITING FUNCTIONALITY\n",
    "    \n",
    "    make_markets_table(markets_data_with_tract)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def make_markets_table(geodataframe):\n",
    "    '''TODO: Docstring\n",
    "    geom_column must be in wkb form'''\n",
    "    \n",
    "    conn = sqlite3.connect('Geospatial_Data/map_data.sqlite')\n",
    "    conn.enable_load_extension(True)\n",
    "    conn.load_extension(\"mod_spatialite\")\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT InitSpatialMetaData(1);\")\n",
    "    \n",
    "    #Generate Schema\n",
    "    create_statement = '''CREATE TABLE IF NOT EXISTS \"markets\"(\n",
    "    \"id\" INTEGER PRIMARY KEY UNIQUE,\n",
    "    \"name\" TEXT,\n",
    "    \"alt_name\" TEXT,\n",
    "    \"addr\" TEXT,\n",
    "    \"shop\" TEXT,\n",
    "    \"opening_hours\" TEXT,\n",
    "    \"phone\" TEXT,\n",
    "    \"GEOID\" TEXT NOT NULL)'''\n",
    "    \n",
    "    \n",
    "    drop_statement = f'''DROP TABLE IF EXISTS \"markets;\"'''\n",
    "    \n",
    "    cur.execute(drop_statement)\n",
    "    cur.execute(create_statement)\n",
    "    \n",
    "    def add_row(row):\n",
    "        add_statement = '''INSERT INTO markets\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)'''\n",
    "        values = row.values.tolist()[:8]\n",
    "        cur.execute(add_statement, values)\n",
    "    \n",
    "    geodataframe.apply(lambda row: add_row(row), axis=1)\n",
    "    \n",
    "    cur.execute(f\"\"\"\n",
    "        SELECT AddGeometryColumn(\"markets\", 'wkb_geometry', '{str(geodataframe.crs)[-4:]}, 'POINT', 2);\n",
    "        \"\"\")\n",
    "    geometry_tuples = []\n",
    "    geodataframe.apply(lambda row: geometry_tuples.append(tuple(row['wkb_geometry'], row['id'])))\n",
    "    \n",
    "    cur.executemany(\n",
    "    f\"\"\"\n",
    "    UPDATE markets\n",
    "    SET wkb_geometry=GeomFromWKB(?, {str(geodataframe.crs)[-4:]})\n",
    "    WHERE markets.id = ?\n",
    "    \"\"\", tuple(geometry_tuples))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_features(feature_df, n, geometry_col, id_col):\n",
    "    '''TODO: Write Docstring'''\n",
    "    ids_with_locations = {}\n",
    "\n",
    "    feature_df['geom_reformat'] = feature_df[geometry_col].apply(lambda location: [location.x, location.y])\n",
    "\n",
    "    df_chunks = np.array_split(feature_df[[id_col, 'geom_reformat']], math.trunc(feature_df.shape[0]/5)+1)\n",
    "\n",
    "    for chunk in df_chunks:\n",
    "        id_string = ''\n",
    "\n",
    "        for item in chunk[id_col].tolist():\n",
    "            id_string += f'{item}_'\n",
    "\n",
    "        location_list = chunk['geom_reformat'].tolist()\n",
    "\n",
    "        ids_with_locations[id_string] = location_list\n",
    "\n",
    "\n",
    "    return ids_with_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isochrones_with_cache(points, layer_cache):\n",
    "    '''TODO: Docstring\n",
    "\n",
    "    Returns dictionary containing an index and a list of GeoJSON Features'''\n",
    "\n",
    "    points_data = gpd.read_file(json.dumps(points))\n",
    "\n",
    "    segments = divide_features(points_data, 5, 'geometry', 'id')\n",
    "\n",
    "    params = {'location_type':'destination',\n",
    "              'range': [600, 420, 300], #420/60 = 7 mins\n",
    "              'range_type': 'time',\n",
    "              'attributes': ['area', 'reachfactor', 'total_pop'], # Get attributes for isochrones\n",
    "              'smoothing': 5\n",
    "             }\n",
    "\n",
    "    header = {\n",
    "        'Accept': 'application/json, application/geo+json, application/gpx+xml, img/png; charset=utf-8',\n",
    "        'Authorization': ORS_KEY,\n",
    "        'Content-Type': 'application/json; charset=utf-8'\n",
    "    }\n",
    "\n",
    "    isochrone_features = layer_cache['GeoJSON']['features']\n",
    "    index = layer_cache['index']\n",
    "\n",
    "    segment_number = 1\n",
    "    for id_string, locations in segments.items():\n",
    "        params['locations'] = locations\n",
    "        params['id'] = id_string\n",
    "        id_list = np.repeat(id_string.split(sep='_'), len(params['range'])).tolist()\n",
    "        index += id_list\n",
    "\n",
    "        try:\n",
    "            isos = requests.post(ORS_URL, json=params, headers=header).json()\n",
    "\n",
    "            i = 0\n",
    "            for feature in isos['features']:\n",
    "                feature['properties']['id'] = id_list[i]\n",
    "                i += 1\n",
    "                isochrone_features.append(feature)\n",
    "\n",
    "            save_cache(layer_cache, layer_cache['GeoJSON']['name'])\n",
    "            print(f\"Fetched New Isochrones: Segment {segment_number} of {len(segments.keys())}\")\n",
    "            segment_number +=1\n",
    "\n",
    "        except:\n",
    "            print(\"Waiting one minute...\")\n",
    "            time.sleep(61)\n",
    "\n",
    "            isos = requests.post(ORS_URL, json=params, headers=header).json()\n",
    "\n",
    "            i = 0\n",
    "            for feature in isos['features']:\n",
    "                feature['properties']['id'] = id_list[i]\n",
    "                i += 1\n",
    "                isochrone_features.append(feature)\n",
    "\n",
    "            save_cache(layer_cache, layer_cache['GeoJSON']['name'])\n",
    "            print(f\"Fetched New Isochrones: Segment {segment_number} of {len(segments.keys())}\")\n",
    "            segment_number +=1\n",
    "\n",
    "    return {'index': index, 'features': isochrone_features}\n",
    "\n",
    "\n",
    "def refresh_isochrones(point_feature_collection, layer_name):\n",
    "    '''TODO: Docstring\n",
    "\n",
    "    point_feature_collection: GeoJSON,\n",
    "    returns GeoJSON of '''\n",
    "\n",
    "    layer_cache = CACHE_VAR.setdefault(f'{layer_name}_isochrones', {'index':[],'GeoJSON':{\n",
    "        'type': 'FeatureCollection',\n",
    "        'name': f'{layer_name}_isochrones',\n",
    "        'features':[]\n",
    "        }\n",
    "        })\n",
    "\n",
    "    features_in_cache = []\n",
    "    features_to_fetch = []\n",
    "\n",
    "    for feature in point_feature_collection['features']:\n",
    "        if str(feature['properties']['id']) in layer_cache['index']:\n",
    "            features_in_cache.append(feature)\n",
    "        else:\n",
    "            features_to_fetch.append(feature)\n",
    "\n",
    "    print(f'''Using {len(features_in_cache)} cached isochrones;\n",
    "                Fetching {len(features_to_fetch)} new isochrones''')\n",
    "\n",
    "    if len(features_to_fetch) >0:\n",
    "        new_isochrones = get_isochrones_with_cache({'type': 'FeatureCollection',\n",
    "                                        'name': 'temp',\n",
    "                                        'features': features_to_fetch}, layer_cache)\n",
    "\n",
    "        layer_cache['index'] += new_isochrones['index']\n",
    "        layer_cache['GeoJSON']['features'] += new_isochrones['features']\n",
    "\n",
    "    save_cache(layer_cache, f'{layer_name}_isochrones')\n",
    "\n",
    "    with open('Geospatial_Data/isochrones.geojson', 'w') as file:\n",
    "        json.dump(layer_cache['GeoJSON'], file, indent=2)\n",
    "\n",
    "    return layer_cache['GeoJSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: http://overpass-api.de/api/interpreter?\n"
     ]
    }
   ],
   "source": [
    "get_market_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'refresh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ef16f7574544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m results = call_API_with_cache(url=overpass_url,\n\u001b[1;32m      7\u001b[0m                               \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moverpass_query_markets\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               cache_name='markets', reset_cache=refresh)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elements'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'refresh' is not defined"
     ]
    }
   ],
   "source": [
    "geographic_elements = {'type':'FeatureCollection',\n",
    "                  'name':'markets',\n",
    "                  'features':[]}\n",
    "\n",
    "\n",
    "results = call_API_with_cache(url=overpass_url,\n",
    "                              params={'data':overpass_query_markets},\n",
    "                              cache_name='markets', reset_cache=refresh)\n",
    "\n",
    "for element in results['elements']:\n",
    "    if 'tags' in element:\n",
    "        geodict = {'type':'Point'}\n",
    "        propdict = {'id':element['id']}\n",
    "\n",
    "        if element['type'] == 'node' and 'tags' in element:\n",
    "            lon = element['lon']\n",
    "            lat = element['lat']\n",
    "            geodict['coordinates'] = [lon, lat]\n",
    "\n",
    "        elif 'center' in element:\n",
    "            lon = element['center']['lon']\n",
    "            lat = element['center']['lat']\n",
    "            geodict['coordinates'] = [lon, lat]\n",
    "\n",
    "        for key, value in element['tags'].items():\n",
    "            propdict[key] = value\n",
    "\n",
    "        geographic_elements['features'].append({'type':'Feature',\n",
    "                                   'geometry':geodict,\n",
    "                                   'properties':propdict})\n",
    "\n",
    "\n",
    "markets_data = gpd.read_file(json.dumps(geographic_elements))\n",
    "markets_data['wkb_geometry'] = markets_data['geometry'].apply(lambda item: item.wkb)\n",
    "markets_data['addr'] = markets_data.apply(lambda row: f\"{row['addr:housenumber']} {row['addr:street']}, {row['addr:city']}\", axis=1)\n",
    "markets_data['addr'] = markets_data['addr'].apply(lambda x: None if (str(x).find('None') != -1) else x)\n",
    "\n",
    "census_tracts = gpd.read_file('Geospatial_Data/NYC_Tracts.geojson').to_crs('epsg:4326')\n",
    "fields_to_keep = ('id', 'name', 'alt_name', 'addr', 'shop', 'opening_hours', 'phone', 'GEOID','wkb_geometry')\n",
    "\n",
    "markets_data_with_tract = gpd.sjoin(markets_data, census_tracts, how='left', op='intersects')\n",
    "markets_data_with_tract.drop(columns=[column for column in markets_data_with_tract.columns \n",
    "                                      if column not in fields_to_keep], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acs_data():\n",
    "    \n",
    "    BASE_URL = 'https://api.census.gov/data/2018/acs/acs5'\n",
    "    county_fips = ['081', '061', '085', '005', '047']\n",
    "    state_fips = '36'\n",
    "    variables = {'total_pop':'B01003_001E',\n",
    "                 'white_pop':'B02001_002E',\n",
    "                 'black_pop':'B02001_003E',\n",
    "                 'aian_pop':'B02001_004E',\n",
    "                 'asian_pop':'B02001_005E',\n",
    "                 'nhpi_pop': 'B02001_006E',\n",
    "                 'other_pop':'B02001_007E',\n",
    "                 'two_or_more_pop':'B02001_008E',\n",
    "                 'median_age':'B01002_001E',\n",
    "                 'median_hh_income':'B19049_001E'\n",
    "                }\n",
    "\n",
    "    tracts_table = gpd.read_file('Geospatial_Data/NYC_Tracts_Clipped.geojson')\n",
    "    \n",
    "    for varname, variable in variables.items():\n",
    "        variable_table = pd.DataFrame({f'{variable}':'Placeholder',\n",
    "                                       'state':'00', \n",
    "                                       'county':'000', \n",
    "                                       'tract':'000000'}, index=[0])\n",
    "        for county in county_fips:\n",
    "            params = {'get':variable,\n",
    "                      'for':'tract:*',\n",
    "                      'in':[f\"state:{state_fips}\",f\"county:{county}\"],\n",
    "                      'key':CENSUS_KEY\n",
    "                   }\n",
    "            \n",
    "            results = call_API_with_cache(url=BASE_URL,\n",
    "                                          params=params,\n",
    "                                          cache_name='census')\n",
    "            variable_table = variable_table.append(pd.DataFrame(results, columns=variable_table.columns).iloc[1:,0:], ignore_index=True)\n",
    "            \n",
    "        tracts_table = tracts_table.merge(variable_table,\n",
    "                                          left_on=['STATEFP', 'COUNTYFP', 'TRACTCE'],\n",
    "                                          right_on=['state', 'county', 'tract'],\n",
    "                                          how='left').drop(columns=['state', 'county', 'tract'])\n",
    "    \n",
    "    tracts_table.to_file('Geospatial_Data/Tracts_with_Data.geojson', driver='GeoJSON')\n",
    "    \n",
    "    return tracts_table\n",
    "            \n",
    "def make_tracts_table(geodataframe):\n",
    "        '''TODO: Docstring'''\n",
    "    \n",
    "        dataframe = geodataframe.drop(columns=['geometry'])'\n",
    "        \n",
    "        schema = '''\"geoid\" TEXT PRIMARY KEY UNIQUE'''\n",
    "        \n",
    "        for column in dataframe.columns.tolist():\n",
    "            if column != 'GEOID':\n",
    "                statement = f''',\n",
    "                \"{str(column).lower()}\" TEXT NOT NULL'''\n",
    "                schema += statement\n",
    "        \n",
    "        drop_statement = '''DROP TABLE IF EXISTS \"tracts\";'''\n",
    "        create_statement = f'''CREATE TABLE IF NOT EXISTS \"tracts\"(\n",
    "        {schema})'''\n",
    "\n",
    "        print(schema)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Index(['STATEFP', 'COUNTYFP', 'TRACTCE', 'GEOID', 'NAME', 'NAMELSAD', 'MTFCC',\n",
      "       'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON', 'geometry',\n",
      "       'B01003_001E', 'B02001_002E', 'B02001_003E', 'B02001_004E',\n",
      "       'B02001_005E', 'B02001_006E', 'B02001_007E', 'B02001_008E',\n",
      "       'B01002_001E', 'B19049_001E'],\n",
      "      dtype='object')\n",
      "STATEFP          object\n",
      "COUNTYFP         object\n",
      "TRACTCE          object\n",
      "GEOID            object\n",
      "NAME             object\n",
      "NAMELSAD         object\n",
      "MTFCC            object\n",
      "FUNCSTAT         object\n",
      "ALAND             int64\n",
      "AWATER            int64\n",
      "INTPTLAT         object\n",
      "INTPTLON         object\n",
      "geometry       geometry\n",
      "B01003_001E      object\n",
      "B02001_002E      object\n",
      "B02001_003E      object\n",
      "B02001_004E      object\n",
      "B02001_005E      object\n",
      "B02001_006E      object\n",
      "B02001_007E      object\n",
      "B02001_008E      object\n",
      "B01002_001E      object\n",
      "B19049_001E      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Tracts\n",
    "tracts = get_acs_data()\n",
    "print(tracts.columns)\n",
    "print(tracts.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEFP</th>\n",
       "      <th>COUNTYFP</th>\n",
       "      <th>TRACTCE</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>NAMELSAD</th>\n",
       "      <th>MTFCC</th>\n",
       "      <th>FUNCSTAT</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLON</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>044800</td>\n",
       "      <td>36081044800</td>\n",
       "      <td>448</td>\n",
       "      <td>Census Tract 448</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>208002</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7110219</td>\n",
       "      <td>-073.8026344</td>\n",
       "      <td>MULTIPOLYGON (((-73.80646 40.71206, -73.80556 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>045800</td>\n",
       "      <td>36081045800</td>\n",
       "      <td>458</td>\n",
       "      <td>Census Tract 458</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>245281</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7152626</td>\n",
       "      <td>-073.7909261</td>\n",
       "      <td>MULTIPOLYGON (((-73.79364 40.71382, -73.79362 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>046200</td>\n",
       "      <td>36081046200</td>\n",
       "      <td>462</td>\n",
       "      <td>Census Tract 462</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>249611</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7098547</td>\n",
       "      <td>-073.7879749</td>\n",
       "      <td>MULTIPOLYGON (((-73.79203 40.71107, -73.79101 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>046300</td>\n",
       "      <td>36081046300</td>\n",
       "      <td>463</td>\n",
       "      <td>Census Tract 463</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>159415</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7440007</td>\n",
       "      <td>-073.8710900</td>\n",
       "      <td>MULTIPOLYGON (((-73.87468 40.74335, -73.87423 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>046400</td>\n",
       "      <td>36081046400</td>\n",
       "      <td>464</td>\n",
       "      <td>Census Tract 464</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>228767</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7168637</td>\n",
       "      <td>-073.7869958</td>\n",
       "      <td>MULTIPOLYGON (((-73.79187 40.71379, -73.79085 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>027900</td>\n",
       "      <td>36081027900</td>\n",
       "      <td>279</td>\n",
       "      <td>Census Tract 279</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>177155</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7516729</td>\n",
       "      <td>-073.8802222</td>\n",
       "      <td>MULTIPOLYGON (((-73.88189 40.75208, -73.88096 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>028000</td>\n",
       "      <td>36081028000</td>\n",
       "      <td>280</td>\n",
       "      <td>Census Tract 280</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>165398</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.6883158</td>\n",
       "      <td>-073.7797191</td>\n",
       "      <td>MULTIPOLYGON (((-73.78243 40.69034, -73.78160 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>028100</td>\n",
       "      <td>36081028100</td>\n",
       "      <td>281</td>\n",
       "      <td>Census Tract 281</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>174444</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.7522203</td>\n",
       "      <td>-073.8825920</td>\n",
       "      <td>MULTIPOLYGON (((-73.88431 40.75567, -73.88351 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>028200</td>\n",
       "      <td>36081028200</td>\n",
       "      <td>282</td>\n",
       "      <td>Census Tract 282</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>182472</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.6849947</td>\n",
       "      <td>-073.7738873</td>\n",
       "      <td>MULTIPOLYGON (((-73.77709 40.68820, -73.77662 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>028400</td>\n",
       "      <td>36081028400</td>\n",
       "      <td>284</td>\n",
       "      <td>Census Tract 284</td>\n",
       "      <td>G5020</td>\n",
       "      <td>S</td>\n",
       "      <td>429455</td>\n",
       "      <td>0</td>\n",
       "      <td>+40.6825033</td>\n",
       "      <td>-073.7778568</td>\n",
       "      <td>MULTIPOLYGON (((-73.78302 40.68428, -73.78213 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2164 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATEFP COUNTYFP TRACTCE        GEOID NAME          NAMELSAD  MTFCC  \\\n",
       "0         36      081  044800  36081044800  448  Census Tract 448  G5020   \n",
       "1         36      081  045800  36081045800  458  Census Tract 458  G5020   \n",
       "2         36      081  046200  36081046200  462  Census Tract 462  G5020   \n",
       "3         36      081  046300  36081046300  463  Census Tract 463  G5020   \n",
       "4         36      081  046400  36081046400  464  Census Tract 464  G5020   \n",
       "...      ...      ...     ...          ...  ...               ...    ...   \n",
       "2159      36      081  027900  36081027900  279  Census Tract 279  G5020   \n",
       "2160      36      081  028000  36081028000  280  Census Tract 280  G5020   \n",
       "2161      36      081  028100  36081028100  281  Census Tract 281  G5020   \n",
       "2162      36      081  028200  36081028200  282  Census Tract 282  G5020   \n",
       "2163      36      081  028400  36081028400  284  Census Tract 284  G5020   \n",
       "\n",
       "     FUNCSTAT   ALAND  AWATER     INTPTLAT      INTPTLON  \\\n",
       "0           S  208002       0  +40.7110219  -073.8026344   \n",
       "1           S  245281       0  +40.7152626  -073.7909261   \n",
       "2           S  249611       0  +40.7098547  -073.7879749   \n",
       "3           S  159415       0  +40.7440007  -073.8710900   \n",
       "4           S  228767       0  +40.7168637  -073.7869958   \n",
       "...       ...     ...     ...          ...           ...   \n",
       "2159        S  177155       0  +40.7516729  -073.8802222   \n",
       "2160        S  165398       0  +40.6883158  -073.7797191   \n",
       "2161        S  174444       0  +40.7522203  -073.8825920   \n",
       "2162        S  182472       0  +40.6849947  -073.7738873   \n",
       "2163        S  429455       0  +40.6825033  -073.7778568   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((-73.80646 40.71206, -73.80556 ...  \n",
       "1     MULTIPOLYGON (((-73.79364 40.71382, -73.79362 ...  \n",
       "2     MULTIPOLYGON (((-73.79203 40.71107, -73.79101 ...  \n",
       "3     MULTIPOLYGON (((-73.87468 40.74335, -73.87423 ...  \n",
       "4     MULTIPOLYGON (((-73.79187 40.71379, -73.79085 ...  \n",
       "...                                                 ...  \n",
       "2159  MULTIPOLYGON (((-73.88189 40.75208, -73.88096 ...  \n",
       "2160  MULTIPOLYGON (((-73.78243 40.69034, -73.78160 ...  \n",
       "2161  MULTIPOLYGON (((-73.88431 40.75567, -73.88351 ...  \n",
       "2162  MULTIPOLYGON (((-73.77709 40.68820, -73.77662 ...  \n",
       "2163  MULTIPOLYGON (((-73.78302 40.68428, -73.78213 ...  \n",
       "\n",
       "[2164 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "Using Cache: https://api.census.gov/data/2018/acs/acs5\n",
      "\"geoid\" TEXT PRIMARY KEY UNIQUE,\n",
      "                \"statefp\" TEXT NOT NULL,\n",
      "                \"countyfp\" TEXT NOT NULL,\n",
      "                \"tractce\" TEXT NOT NULL,\n",
      "                \"name\" TEXT NOT NULL,\n",
      "                \"namelsad\" TEXT NOT NULL,\n",
      "                \"mtfcc\" TEXT NOT NULL,\n",
      "                \"funcstat\" TEXT NOT NULL,\n",
      "                \"aland\" TEXT NOT NULL,\n",
      "                \"awater\" TEXT NOT NULL,\n",
      "                \"intptlat\" TEXT NOT NULL,\n",
      "                \"intptlon\" TEXT NOT NULL,\n",
      "                \"b01003_001e\" TEXT NOT NULL,\n",
      "                \"b02001_002e\" TEXT NOT NULL,\n",
      "                \"b02001_003e\" TEXT NOT NULL,\n",
      "                \"b02001_004e\" TEXT NOT NULL,\n",
      "                \"b02001_005e\" TEXT NOT NULL,\n",
      "                \"b02001_006e\" TEXT NOT NULL,\n",
      "                \"b02001_007e\" TEXT NOT NULL,\n",
      "                \"b02001_008e\" TEXT NOT NULL,\n",
      "                \"b01002_001e\" TEXT NOT NULL,\n",
      "                \"b19049_001e\" TEXT NOT NULL\n"
     ]
    }
   ],
   "source": [
    "make_tracts_table(get_acs_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
